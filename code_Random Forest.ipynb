{"cells":[{"cell_type":"markdown","id":"b29c8168","metadata":{},"source":["# 데이터 로드"]},{"cell_type":"code","execution_count":44,"id":"5adfb909","metadata":{},"outputs":[],"source":["import os\n","from pprint import pprint\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# %mathplotlib inline\n","import pandas as pd\n","from tqdm import tqdm\n","from imblearn.over_sampling import SMOTE\n","from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import IsolationForest\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import (\n","    accuracy_score,\n","    classification_report,\n","    confusion_matrix,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n",")"]},{"cell_type":"markdown","id":"42d3fa94","metadata":{},"source":["## train 데이터"]},{"cell_type":"code","execution_count":45,"id":"8ce910d6","metadata":{},"outputs":[],"source":["ROOT_DIR = \"data\"\n","RANDOM_STATE = 42\n","\n","train_df = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))\n","\n","df_train = train_df\n","# display(df_train)\n","\n","X_train = train_df.iloc[:,:-1]\n","# display(X_train)\n","\n","y_train = train_df.iloc[:,-1]\n","# display(y_train)"]},{"cell_type":"markdown","id":"7b2aa7d4","metadata":{},"source":["## test 데이터"]},{"cell_type":"code","execution_count":46,"id":"52d82fdf","metadata":{},"outputs":[],"source":["df = pd.read_csv(os.path.join(ROOT_DIR, \"test.csv\"))\n","X_test = df.drop(columns = ['Set ID'])\n","# display(X_test)"]},{"cell_type":"markdown","id":"bc7197d7","metadata":{},"source":["# 데이터 전처리\n","## 오입력 값 결측치로 바꾸기"]},{"cell_type":"code","execution_count":47,"id":"6444add9","metadata":{},"outputs":[],"source":["X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] = X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].replace('OK',np.nan)\n","X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] = X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].replace('OK',np.nan)\n","\n","X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] = X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].replace('OK',np.nan)\n","X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] = X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].replace('OK',np.nan)\n","\n","X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] = X_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].replace('OK',np.nan)\n","X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] = X_test['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].replace('OK',np.nan)\n","\n","df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'].replace('OK',np.nan)\n","df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].replace('OK',np.nan)\n","df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'] = df_train['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].replace('OK',np.nan)"]},{"cell_type":"markdown","id":"2ae412fe","metadata":{},"source":["## 결측치 처리\n","### 결측치 비율이 50%가 넘는 컬럼 제거"]},{"cell_type":"code","execution_count":48,"id":"07a476be","metadata":{},"outputs":[],"source":["def highly_null(df, threshold=0.3):\n","    df_copy = df.copy()\n","    missing_ratio = df_copy.isnull().mean()\n","    \n","    null_columns = df_copy.columns[missing_ratio > threshold]\n","    df_copy.drop(columns = null_columns, inplace = True)    \n","    return df_copy\n","\n","X_train = highly_null(X_train)\n","# display(X_train)\n","\n","X_test = highly_null(X_test)\n","# display(X_test)\n","\n","df_train = highly_null(df_train)\n","# display(df_train)"]},{"cell_type":"markdown","id":"6ff7aad7","metadata":{},"source":["## train, validation 데이터 나누기"]},{"cell_type":"code","execution_count":49,"id":"9242f9b0","metadata":{},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_STATE)\n","\n","df_train = pd.concat([X_train, y_train], axis=1)\n","# display(df_train)"]},{"cell_type":"markdown","id":"d058138e","metadata":{},"source":["## 이상치 제거(train 데이터에만)"]},{"cell_type":"code","execution_count":17,"id":"fd1ddd6f","metadata":{},"outputs":[],"source":["# def isolation_forest(df):\n","\n","#     # 숫자형 데이터만 선택\n","#     df_numeric = df.select_dtypes(include=['number'])\n","\n","#     # Isolation Forest 모델 초기화\n","#     iso_forest = IsolationForest(contamination=0.05, random_state=42)\n","#     iso_forest.fit(df_numeric)\n","#     y_pred = iso_forest.predict(df_numeric)\n","\n","#     # 원래 데이터프레임에 예측 결과 추가\n","#     df['Prediction'] = y_pred\n","\n","#     # 이상치와 정상 데이터로 구분\n","#     df_normal = df[df['Prediction'] == 1]\n","#     df_outliers = df[df['Prediction'] == -1]\n","    \n","#     return df_normal\n","\n","# df_train_outlier = isolation_forest(df_train)\n","# # display(df_train_outlier)"]},{"cell_type":"code","execution_count":50,"id":"e92fcee5","metadata":{},"outputs":[],"source":["df_train_outlier = df_train\n","\n","#df_train_outlier.drop(columns = ['Prediction'], inplace = True)\n","# display(df_train_outlier)\n","\n","X_train_outlier = df_train_outlier.iloc[:,:-1]\n","# display(X_train_outlier)\n","\n","y_train_outlier = df_train_outlier.iloc[:,-1]\n","# display(y_train_outlier)"]},{"cell_type":"markdown","id":"ba1d363e","metadata":{},"source":["## 데이터 스케일링(Robust Scaler)"]},{"cell_type":"code","execution_count":51,"id":"88b39482","metadata":{},"outputs":[],"source":["X_numerical_train_outlier = X_train_outlier[X_train_outlier.select_dtypes(include=['number']).columns]\n","X_categorical_train_outlier = X_train_outlier[X_train_outlier.select_dtypes(include=['object', 'category']).columns]\n","# display(X_numerical_train_outlier)\n","\n","X_numerical_val_outlier = X_val[X_val.select_dtypes(include=['number']).columns]\n","X_categorical_val_outlier = X_val[X_val.select_dtypes(include=['object', 'category']).columns]\n","\n","X_numerical_test = X_test[X_test.select_dtypes(include=['number']).columns]\n","X_categorical_test = X_test[X_test.select_dtypes(include=['object', 'category']).columns]\n","# display(X_numerical_test)\n","\n","scaler_outlier = RobustScaler()\n","scaler_outlier.fit(X_numerical_train_outlier)\n","\n","X_numerical_train_outlier_scaled = scaler_outlier.transform(X_numerical_train_outlier)\n","X_numerical_val_outlier_scaled = scaler_outlier.transform(X_numerical_val_outlier)\n","X_numerical_test_outlier_scaled = scaler_outlier.transform(X_numerical_test)\n","\n","X_numerical_train_outlier_scaled_df = pd.DataFrame(X_numerical_train_outlier_scaled,\n","                                          columns = X_numerical_train_outlier.columns)\n","X_numerical_val_outlier_scaled_df = pd.DataFrame(X_numerical_val_outlier_scaled,\n","                                        columns = X_numerical_val_outlier.columns)\n","X_numerical_test_outlier_scaled_df = pd.DataFrame(X_numerical_test_outlier_scaled,\n","                                        columns = X_numerical_test.columns)\n","\n","X_categorical_train_outlier_df = pd.DataFrame(X_categorical_train_outlier, \n","                                   columns=X_categorical_train_outlier.columns)\n","X_categorical_val_outlier_df = pd.DataFrame(X_categorical_val_outlier, \n","                                 columns=X_categorical_val_outlier.columns)\n","X_categorical_test_outlier_df = pd.DataFrame(X_categorical_test, \n","                                 columns=X_categorical_test.columns)\n","\n","X_train_outlier_scaled = pd.concat([X_numerical_train_outlier_scaled_df, \n","                            X_categorical_train_outlier_df.reset_index(drop=True)], axis=1)\n","X_val_outlier_scaled = pd.concat([X_numerical_val_outlier_scaled_df, \n","                          X_categorical_val_outlier_df.reset_index(drop=True)], axis=1)\n","X_test_outlier_scaled = pd.concat([X_numerical_test_outlier_scaled_df, \n","                          X_categorical_test_outlier_df.reset_index(drop=True)], axis=1)\n"]},{"cell_type":"markdown","id":"a957c584","metadata":{},"source":["## 문자형 데이터를 숫자형으로 변경(Ordinal Encoder)"]},{"cell_type":"code","execution_count":52,"id":"13caff79","metadata":{},"outputs":[],"source":["encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n","\n","# 범주형 컬럼만 선택\n","train_outlier_categorical_cols = X_train_outlier_scaled.select_dtypes(include=['object']).columns\n","val_outlier_categorical_cols = X_val_outlier_scaled.select_dtypes(include=['object']).columns\n","test_outlier_categorical_cols = X_test_outlier_scaled.select_dtypes(include=['object']).columns\n","\n","# 범주형 데이터에만 LabelEncoder 적용\n","X_train_outlier_scaled[train_outlier_categorical_cols] = encoder.fit_transform(X_train_outlier_scaled[train_outlier_categorical_cols])\n","X_val_outlier_scaled[val_outlier_categorical_cols] = encoder.transform(X_val_outlier_scaled[val_outlier_categorical_cols])\n","X_test_outlier_scaled[test_outlier_categorical_cols] = encoder.transform(X_test_outlier_scaled[test_outlier_categorical_cols])"]},{"cell_type":"markdown","id":"c4c84eae","metadata":{},"source":["# SMOTE 샘플링"]},{"cell_type":"code","execution_count":53,"id":"61db18d5","metadata":{},"outputs":[],"source":["y_train_outlier.replace({'Normal':0, 'AbNormal':1}, inplace=True)\n","y_val.replace({'Normal':0, 'AbNormal':1}, inplace=True)"]},{"cell_type":"code","execution_count":54,"id":"bc07005f","metadata":{},"outputs":[],"source":["smote = SMOTE(random_state=0, sampling_strategy='not minority')\n","# smote = SMOTE(random_state=0)\n","X_resampled_outlier, y_resampled_outlier = smote.fit_resample(X_train_outlier_scaled, y_train_outlier)"]},{"cell_type":"code","execution_count":192,"id":"016dd5eb","metadata":{},"outputs":[{"data":{"text/plain":["target\n","Normal      34332\n","AbNormal     2123\n","Name: count, dtype: int64"]},"execution_count":192,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts()"]},{"cell_type":"code","execution_count":193,"id":"b137e1f0","metadata":{},"outputs":[{"data":{"text/plain":["target\n","0    32611\n","1     2021\n","Name: count, dtype: int64"]},"execution_count":193,"metadata":{},"output_type":"execute_result"}],"source":["y_resampled_outlier.value_counts()"]},{"cell_type":"markdown","id":"25ebc55e","metadata":{},"source":["## PCA"]},{"cell_type":"code","execution_count":60,"id":"4f90bbd5","metadata":{},"outputs":[],"source":["# 예시로 3개의 클러스터로 데이터 클러스터링\n","kmeans = KMeans(n_clusters=5, random_state=RANDOM_STATE)\n","X_clustered = kmeans.fit_predict(X_resampled_outlier)\n","\n","# 클러스터 레이블을 원래 데이터에 추가\n","X_resampled_with_cluster = np.c_[X_resampled_outlier, X_clustered]"]},{"cell_type":"code","execution_count":61,"id":"da2b30c3","metadata":{},"outputs":[],"source":["# 예시로 2개의 주성분으로 차원 축소\n","pca = PCA(n_components=5)\n","X_pca = pca.fit_transform(X_resampled_with_cluster)\n","\n","X_val_clustered = np.c_[X_val_outlier_scaled, kmeans.predict(X_val_outlier_scaled)]\n","X_val_pca = pca.transform(X_val_clustered)\n","\n","X_test_clustered = np.c_[X_test_outlier_scaled, kmeans.predict(X_test_outlier_scaled)]\n","X_test_pca = pca.transform(X_test_clustered)"]},{"cell_type":"markdown","id":"7d0ffeaa","metadata":{},"source":["## LDA"]},{"cell_type":"code","execution_count":31,"id":"ecf7057b","metadata":{},"outputs":[],"source":["# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","\n","# # y_resampled에서 클래스 수 확인\n","# n_classes = len(np.unique(y_resampled_outlier))\n","\n","# # 피처 수 및 LDA의 최대 가능한 차원 수 계산\n","# n_features = X_resampled_with_cluster.shape[1]\n","# max_components = min(n_features, n_classes - 1)\n","\n","# # LDA로 차원 축소 (n_components는 max_components 이하로 설정)\n","# lda = LDA(n_components=max_components)\n","# X_pca = lda.fit_transform(X_resampled_with_cluster, y_resampled_outlier)\n","\n","# X_val_clustered = np.c_[X_val_outlier_scaled, kmeans.predict(X_val_outlier_scaled)]\n","# X_val_pca = lda.transform(X_val_clustered)\n","\n","# X_test_clustered = np.c_[X_test_outlier_scaled, kmeans.predict(X_test_outlier_scaled)]\n","# X_test_pca = lda.transform(X_test_clustered)"]},{"cell_type":"markdown","id":"2ede9c88","metadata":{},"source":["# 모델 학습\n","## 평가지표"]},{"cell_type":"code","execution_count":57,"id":"4c58747c","metadata":{},"outputs":[],"source":["def get_clf_eval(y_test, pred=None):\n","    confusion = confusion_matrix( y_test, pred)\n","    accuracy = accuracy_score(y_test , pred)\n","    precision = precision_score(y_test , pred)\n","    recall = recall_score(y_test , pred)\n","    f1 = f1_score(y_test,pred)\n","    print('오차 행렬')\n","    print(confusion)\n","    print('정확도: {0:.4f}\\n정밀도: {1:.4f}\\n재현율: {2:.4f}\\n  F1: {3:.4f}'.format(accuracy, precision, recall, f1))"]},{"cell_type":"markdown","id":"247cc4d1","metadata":{},"source":["## 랜덤포레스트"]},{"cell_type":"code","execution_count":62,"id":"0059d364","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["오차 행렬\n","[[3663  161]\n"," [ 181   46]]\n","정확도: 0.9156\n","정밀도: 0.2222\n","재현율: 0.2026\n","  F1: 0.2120\n"]}],"source":["# n_estimators : 트리의 개수 (기본값 100)\n","# criterion : 불순도 계산 방법 (기본값 gini) (gini, entropy, log_loss)\n","# max_depth : 트리의 최대 깊이 (기본값 None) none이면 모든 리프가 순수해질 때까지 모든 리프에 min_samples_split개수보다 적은 샘플이 남을 때까지 확장\n","# min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터 수 (기본값 2)\n","# min_samples_leaf : 리프 노드가 되기 위해 필요한 최소한의 샘플 데이터 수 (기본값 1)\n","RF = RandomForestClassifier(\n","    random_state=42, \n","    n_jobs=-1,\n","    n_estimators=200,\n","    criterion='entropy',\n","    max_depth=None,\n","    min_samples_split=2,\n","    min_samples_leaf=1\n",")\n","RF.fit(X_pca, y_resampled_outlier)\n","\n","# preds = RF.predict(X_val_pca)\n","\n","probs = RF.predict_proba(X_val_pca)[:,1]\n","preds = (probs > 0.3).astype(int)\n","\n","get_clf_eval(y_val, preds)"]},{"cell_type":"markdown","id":"07484d6b","metadata":{},"source":["# 제출하기"]},{"cell_type":"code","execution_count":32,"id":"d846ff2e","metadata":{},"outputs":[{"data":{"text/plain":["985"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# test_pred = RF.predict(X_test_pca)\n","\n","test_prob = RF.predict_proba(X_test_pca)[:,1]\n","test_pred = (test_prob > 0.3).astype(int)\n","\n","test_pred = np.where(test_pred==0, 'Normal', 'AbNormal')\n","np.sum(test_pred == 'AbNormal')"]},{"cell_type":"code","execution_count":141,"id":"974c04fd","metadata":{},"outputs":[],"source":["# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n","df_sub = pd.read_csv(\"submission.csv\")\n","len(df_sub)\n","df_sub[\"target\"] = test_pred\n","\n","# 제출 파일 저장\n","df_sub.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"markdown","id":"22ac1099","metadata":{},"source":["## Grid Search"]},{"cell_type":"code","execution_count":null,"id":"5b772a28","metadata":{},"outputs":[],"source":["params = {  \n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","model = RandomForestClassifier(random_state=RANDOM_STATE)\n","grid_search = GridSearchCV(estimator=model, param_grid=params, \n","                           scoring='f1_weighted', cv=3, verbose=2, n_jobs=-1)\n","grid_search.fit(X_pca, y_resampled_outlier)\n","\n","print('최적 하이퍼 파라미터:\\n', grid_search.best_params_)\n","print('최고 예측 정확도: {0:.4f}'.format(grid_search.best_score_))\n","\n","best_model = grid_search.best_estimator_\n","display(best_model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
